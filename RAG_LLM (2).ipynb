{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98682006",
   "metadata": {},
   "source": [
    "## Install Important packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d71243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (0.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.9 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.0.10)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.7 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.1.8)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.0.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (3.5.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.7->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.7->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "675112c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: google-auth in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.26.1)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (2.15.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.7.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.62.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (4.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6024c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (0.0.5)\n",
      "Requirement already satisfied: google-generativeai<0.4.0,>=0.3.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.3.2)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.1.8)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.0)\n",
      "Requirement already satisfied: google-auth in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.26.1)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.15.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.7.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.25.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.23.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (0.0.77)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.10.8)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (8.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2023.7.22)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.62.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.60.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.60.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42a49b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\kushal.sharma\\appdata\\local\\anaconda3\\lib\\site-packages (1.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425dd264",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a650febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d89685",
   "metadata": {},
   "source": [
    "## Initializing an instance of a Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1e3887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf6a9b",
   "metadata": {},
   "source": [
    "## Load the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "478f7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document, split it into chunks, embed each chunk, and load it into the vector store.\n",
    "raw_documents = TextLoader('xyz.txt').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0a5dd",
   "metadata": {},
   "source": [
    "## Chunking the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7f36f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 471, which is longer than the specified 20\n",
      "Created a chunk of size 727, which is longer than the specified 20\n",
      "Created a chunk of size 673, which is longer than the specified 20\n",
      "Created a chunk of size 399, which is longer than the specified 20\n",
      "Created a chunk of size 335, which is longer than the specified 20\n",
      "Created a chunk of size 687, which is longer than the specified 20\n",
      "Created a chunk of size 392, which is longer than the specified 20\n",
      "Created a chunk of size 406, which is longer than the specified 20\n",
      "Created a chunk of size 401, which is longer than the specified 20\n",
      "Created a chunk of size 676, which is longer than the specified 20\n",
      "Created a chunk of size 319, which is longer than the specified 20\n",
      "Created a chunk of size 316, which is longer than the specified 20\n",
      "Created a chunk of size 218, which is longer than the specified 20\n",
      "Created a chunk of size 527, which is longer than the specified 20\n",
      "Created a chunk of size 310, which is longer than the specified 20\n",
      "Created a chunk of size 370, which is longer than the specified 20\n",
      "Created a chunk of size 377, which is longer than the specified 20\n",
      "Created a chunk of size 519, which is longer than the specified 20\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=20, chunk_overlap=5)    # take 1/5 ratio mostly \n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a68e5",
   "metadata": {},
   "source": [
    "## Printing Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a844385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('page_content', \"LLM, short for Master of Laws, is an advanced and specialized postgraduate degree in law. It's designed for individuals who already possess a foundational understanding of law and wish to deepen their expertise in a specific area. The curriculum typically covers a wide array of legal subjects, offering students the flexibility to focus on specialized fields like international law, corporate law, intellectual property, human rights, or environmental law, among others.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'The pursuit of an LLM offers numerous benefits. It allows individuals to gain in-depth knowledge, critical analysis skills, and a nuanced understanding of legal frameworks within their chosen concentration. This advanced degree can significantly enhance career prospects, offering opportunities in academia, law practice, government, or international organizations.Moreover, an LLM often facilitates global networking, enabling students to interact with legal professionals, scholars, and experts from diverse cultural and legal backgrounds. Many institutions offering LLM programs encourage interactive learning, research, and the exploration of real-world legal challenges, providing a rich and immersive academic experience.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', \"Overall, an LLM serves as a gateway for legal professionals seeking to excel in their specialized areas, contributing to the dynamic and evolving landscape of law and its applications across various domains globally.ChatGPT stands as a pinnacle in natural language processing, representing an advanced form of AI-driven conversational models. Developed by OpenAI, ChatGPT harnesses the power of deep learning and large-scale neural networks to understand, generate, and respond to human language. It's a cutting-edge language model designed to comprehend context, structure, and nuances in conversations, enabling it to produce coherent and contextually relevant responses.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'Operating on a vast corpus of diverse textual data, ChatGPT learns patterns, semantics, and linguistic nuances, empowering it to simulate human-like conversations across a spectrum of topics and domains. Through continual learning and exposure to vast volumes of text, it adapts to understand slang, idiomatic expressions, and varied writing styles, enhancing its conversational abilities over time.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'The versatility of ChatGPT allows it to be deployed in numerous applications, including customer service, content generation, language translation, and educational assistance. Its adaptability to different domains and its ability to maintain engaging dialogues have made it a cornerstone in revolutionizing human-computer interactions.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'Despite its remarkable capabilities, ChatGPT is continuously evolving, with ongoing advancements aimed at refining its understanding, empathy, and ability to generate more contextually appropriate and helpful responses. As AI continues to progress, ChatGPT stands as a pioneering example of the possibilities and potential of natural language understanding and generation.LangChain represents a groundbreaking initiative at the intersection of language technology, blockchain, and community-driven innovation. Positioned as a collaborative platform, LangChain aims to revolutionize linguistic applications, fostering a decentralized ecosystem for language-related services and solutions.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'At its core, LangChain seeks to address multifaceted challenges within language technology, including translation, natural language processing, linguistic data management, and accessibility. Leveraging the power of blockchain technology, it endeavors to create a secure, transparent, and inclusive environment for linguistic data sharing, AI model training, and language-related applications.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', \"By integrating blockchain's immutable ledger and smart contracts, LangChain facilitates secure transactions, incentivizes contributions, and ensures fair compensation for linguistic data providers, developers, and participants in the ecosystem. This framework encourages collaboration, innovation, and the democratization of language resources, transcending geographical boundaries and linguistic barriers.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'Moreover, LangChain envisions a community-driven approach, where stakeholders actively engage, contribute, and shape the development of language technologies. Through open-source frameworks and participatory governance, it fosters an inclusive environment for developers, researchers, linguists, and language enthusiasts to collaborate, share insights, and co-create transformative language solutions.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'In essence, LangChain aspires to unlock the vast potential of language technology by fostering a decentralized, collaborative ecosystem that empowers diverse communities, accelerates innovation, and propels the evolution of linguistic applications to new heights.Bard, in the realm of medieval history and literature, holds a distinguished position as a multifaceted and revered figure. Originating in Celtic cultures, the bard was more than a mere entertainer or musician; they were custodians of tradition, storytellers, poets, and musicians rolled into one. Their role extended beyond performance; they were repositories of cultural knowledge, history, and communal wisdom.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', \"Bards were tasked with preserving and disseminating the rich tapestry of their society's oral traditions, conveying narratives of heroism, myth, and moral lessons through their lyrical compositions. Their performances transcended mere entertainment, serving as a conduit for cultural transmission and societal cohesion.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'Their proficiency in composing and reciting poetry, coupled with musical prowess, enabled bards to captivate audiences and evoke emotions ranging from joy to contemplation. Often revered and patronized by nobility, bards enjoyed a special status, their artistry and knowledge valued highly in courts and communities.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'Moreover, their narratives often held societal critiques, acting as a mirror to the prevailing socio-political landscape. Bards wielded significant influence through their ability to shape opinions and provoke thought.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', \"In essence, the bard was a revered figure, an artist, historian, and custodian of culture, whose legacy continues to resonate through literary traditions and the enduring enchantment of their timeless tales.ChatGPT is an advanced language model developed by OpenAI, specifically designed for natural language processing (NLP) and generating human-like text. It's part of the broader GPT (Generative Pre-trained Transformer) series, renowned for its proficiency in understanding, generating, and responding to text-based inputs.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'ChatGPT is based on a deep learning architecture called the Transformer model, specifically trained on vast amounts of text data from the internet. This extensive training enables ChatGPT to comprehend and generate coherent, contextually relevant text across a wide range of topics and conversational contexts.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', \"The model's capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', \"ChatGPT's applications span various domains, including customer service chatbots, content generation, language translation, educational tools, and more. Its adaptability, language fluency, and ability to maintain engaging conversations have made it a significant advancement in AI-driven conversational models, continually evolving through ongoing improvements and refinements.\"), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n",
      "[('page_content', 'Overall, ChatGPT represents a milestone in natural language understanding and generation, demonstrating the potential of AI to comprehend and generate text in a manner that closely mimics human conversation.Large Language Models (LLMs) have emerged as transformative forces in the world of artificial intelligence, blurring the lines between machine and human communication. Understanding these complex systems requires venturing into the intricate labyrinth of language, where massive data meets algorithmic ingenuity.'), ('metadata', {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}), ('type', 'Document')]\n"
     ]
    }
   ],
   "source": [
    "for chunks in documents:\n",
    "    print(list(chunks))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee4d69d",
   "metadata": {},
   "source": [
    "## Creating embeddings and storing in vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d37a80b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace 'model_name' with the actual model name or identifier\n",
    "model_name = \"models/embedding-001\"\n",
    "api_key = \"your api key \"  # Replace with your Google API key\n",
    "\n",
    "embeddingsss = GoogleGenerativeAIEmbeddings(model=model_name, google_api_key=api_key) # creating embeddings\n",
    "\n",
    "db = FAISS.from_documents(documents, embeddingsss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b81fed",
   "metadata": {},
   "source": [
    "## Writing Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab4c3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is chatgpt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce69db3",
   "metadata": {},
   "source": [
    "## Retrieving matching results from db (vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a80fdb89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"The model's capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate.\", metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}),\n",
       " Document(page_content='The versatility of ChatGPT allows it to be deployed in numerous applications, including customer service, content generation, language translation, and educational assistance. Its adaptability to different domains and its ability to maintain engaging dialogues have made it a cornerstone in revolutionizing human-computer interactions.', metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}),\n",
       " Document(page_content='ChatGPT is based on a deep learning architecture called the Transformer model, specifically trained on vast amounts of text data from the internet. This extensive training enables ChatGPT to comprehend and generate coherent, contextually relevant text across a wide range of topics and conversational contexts.', metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}),\n",
       " Document(page_content=\"ChatGPT's applications span various domains, including customer service chatbots, content generation, language translation, educational tools, and more. Its adaptability, language fluency, and ability to maintain engaging conversations have made it a significant advancement in AI-driven conversational models, continually evolving through ongoing improvements and refinements.\", metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'})]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b335a8",
   "metadata": {},
   "source": [
    "## similarity_search_by_vector in db(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a96a754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate.\n"
     ]
    }
   ],
   "source": [
    "query = \"what is chatgpt \"\n",
    "embedding_vector = embeddingsss.embed_query(query)\n",
    "docs_and_scores = db.similarity_search_by_vector(embedding_vector)\n",
    "print(docs_and_scores[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4497052b",
   "metadata": {},
   "source": [
    "## similarity_search_with_score in db(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66bdad34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: The model's capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}, Score: 0.29974237084388733\n",
      "Content: The versatility of ChatGPT allows it to be deployed in numerous applications, including customer service, content generation, language translation, and educational assistance. Its adaptability to different domains and its ability to maintain engaging dialogues have made it a cornerstone in revolutionizing human-computer interactions., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}, Score: 0.31110721826553345\n",
      "Content: ChatGPT is based on a deep learning architecture called the Transformer model, specifically trained on vast amounts of text data from the internet. This extensive training enables ChatGPT to comprehend and generate coherent, contextually relevant text across a wide range of topics and conversational contexts., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}, Score: 0.32082056999206543\n",
      "Content: ChatGPT's applications span various domains, including customer service chatbots, content generation, language translation, educational tools, and more. Its adaptability, language fluency, and ability to maintain engaging conversations have made it a significant advancement in AI-driven conversational models, continually evolving through ongoing improvements and refinements., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}, Score: 0.32194268703460693\n"
     ]
    }
   ],
   "source": [
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43eb6c",
   "metadata": {},
   "source": [
    "## similarity_search in db(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f6879fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"The model's capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate.\", metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}),\n",
       " Document(page_content='The versatility of ChatGPT allows it to be deployed in numerous applications, including customer service, content generation, language translation, and educational assistance. Its adaptability to different domains and its ability to maintain engaging dialogues have made it a cornerstone in revolutionizing human-computer interactions.', metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}),\n",
       " Document(page_content='ChatGPT is based on a deep learning architecture called the Transformer model, specifically trained on vast amounts of text data from the internet. This extensive training enables ChatGPT to comprehend and generate coherent, contextually relevant text across a wide range of topics and conversational contexts.', metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}),\n",
       " Document(page_content=\"ChatGPT's applications span various domains, including customer service chatbots, content generation, language translation, educational tools, and more. Its adaptability, language fluency, and ability to maintain engaging conversations have made it a significant advancement in AI-driven conversational models, continually evolving through ongoing improvements and refinements.\", metadata={'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9f83a",
   "metadata": {},
   "source": [
    "## Fetching Top K Results from db(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "90177c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: The model's capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: The versatility of ChatGPT allows it to be deployed in numerous applications, including customer service, content generation, language translation, and educational assistance. Its adaptability to different domains and its ability to maintain engaging dialogues have made it a cornerstone in revolutionizing human-computer interactions., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: ChatGPT is based on a deep learning architecture called the Transformer model, specifically trained on vast amounts of text data from the internet. This extensive training enables ChatGPT to comprehend and generate coherent, contextually relevant text across a wide range of topics and conversational contexts., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: ChatGPT's applications span various domains, including customer service chatbots, content generation, language translation, educational tools, and more. Its adaptability, language fluency, and ability to maintain engaging conversations have made it a significant advancement in AI-driven conversational models, continually evolving through ongoing improvements and refinements., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: Operating on a vast corpus of diverse textual data, ChatGPT learns patterns, semantics, and linguistic nuances, empowering it to simulate human-like conversations across a spectrum of topics and domains. Through continual learning and exposure to vast volumes of text, it adapts to understand slang, idiomatic expressions, and varied writing styles, enhancing its conversational abilities over time., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: Overall, ChatGPT represents a milestone in natural language understanding and generation, demonstrating the potential of AI to comprehend and generate text in a manner that closely mimics human conversation.Large Language Models (LLMs) have emerged as transformative forces in the world of artificial intelligence, blurring the lines between machine and human communication. Understanding these complex systems requires venturing into the intricate labyrinth of language, where massive data meets algorithmic ingenuity., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: Despite its remarkable capabilities, ChatGPT is continuously evolving, with ongoing advancements aimed at refining its understanding, empathy, and ability to generate more contextually appropriate and helpful responses. As AI continues to progress, ChatGPT stands as a pioneering example of the possibilities and potential of natural language understanding and generation.LangChain represents a groundbreaking initiative at the intersection of language technology, blockchain, and community-driven innovation. Positioned as a collaborative platform, LangChain aims to revolutionize linguistic applications, fostering a decentralized ecosystem for language-related services and solutions., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: Overall, an LLM serves as a gateway for legal professionals seeking to excel in their specialized areas, contributing to the dynamic and evolving landscape of law and its applications across various domains globally.ChatGPT stands as a pinnacle in natural language processing, representing an advanced form of AI-driven conversational models. Developed by OpenAI, ChatGPT harnesses the power of deep learning and large-scale neural networks to understand, generate, and respond to human language. It's a cutting-edge language model designed to comprehend context, structure, and nuances in conversations, enabling it to produce coherent and contextually relevant responses., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: In essence, the bard was a revered figure, an artist, historian, and custodian of culture, whose legacy continues to resonate through literary traditions and the enduring enchantment of their timeless tales.ChatGPT is an advanced language model developed by OpenAI, specifically designed for natural language processing (NLP) and generating human-like text. It's part of the broader GPT (Generative Pre-trained Transformer) series, renowned for its proficiency in understanding, generating, and responding to text-based inputs., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n",
      "Content: Moreover, LangChain envisions a community-driven approach, where stakeholders actively engage, contribute, and shape the development of language technologies. Through open-source frameworks and participatory governance, it fosters an inclusive environment for developers, researchers, linguists, and language enthusiasts to collaborate, share insights, and co-create transformative language solutions., Metadata: {'source': 'C:\\\\Users\\\\Kushal.Sharma\\\\Desktop\\\\Example_Rag.txt'}\n"
     ]
    }
   ],
   "source": [
    "results = db.similarity_search(query , k= 10)\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72adccd",
   "metadata": {},
   "source": [
    "## Generating Final Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d3d625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given the following text chunks:\\n[Document(page_content=\"The model\\'s capabilities encompass understanding nuances in language, syntax, grammar, semantics, and context, allowing it to engage in diverse and coherent conversations. Whether answering questions, assisting with tasks, or engaging in casual dialogue, ChatGPT aims to simulate human-like conversation and generate text that feels natural and contextually appropriate.\", metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\\'The versatility of ChatGPT allows it to be deployed in numerous applications, including customer service, content generation, language translation, and educational assistance. Its adaptability to different domains and its ability to maintain engaging dialogues have made it a cornerstone in revolutionizing human-computer interactions.\\', metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\\'ChatGPT is based on a deep learning architecture called the Transformer model, specifically trained on vast amounts of text data from the internet. This extensive training enables ChatGPT to comprehend and generate coherent, contextually relevant text across a wide range of topics and conversational contexts.\\', metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\"ChatGPT\\'s applications span various domains, including customer service chatbots, content generation, language translation, educational tools, and more. Its adaptability, language fluency, and ability to maintain engaging conversations have made it a significant advancement in AI-driven conversational models, continually evolving through ongoing improvements and refinements.\", metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\\'Operating on a vast corpus of diverse textual data, ChatGPT learns patterns, semantics, and linguistic nuances, empowering it to simulate human-like conversations across a spectrum of topics and domains. Through continual learning and exposure to vast volumes of text, it adapts to understand slang, idiomatic expressions, and varied writing styles, enhancing its conversational abilities over time.\\', metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\\'Overall, ChatGPT represents a milestone in natural language understanding and generation, demonstrating the potential of AI to comprehend and generate text in a manner that closely mimics human conversation.Large Language Models (LLMs) have emerged as transformative forces in the world of artificial intelligence, blurring the lines between machine and human communication. Understanding these complex systems requires venturing into the intricate labyrinth of language, where massive data meets algorithmic ingenuity.\\', metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\\'Despite its remarkable capabilities, ChatGPT is continuously evolving, with ongoing advancements aimed at refining its understanding, empathy, and ability to generate more contextually appropriate and helpful responses. As AI continues to progress, ChatGPT stands as a pioneering example of the possibilities and potential of natural language understanding and generation.LangChain represents a groundbreaking initiative at the intersection of language technology, blockchain, and community-driven innovation. Positioned as a collaborative platform, LangChain aims to revolutionize linguistic applications, fostering a decentralized ecosystem for language-related services and solutions.\\', metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\"Overall, an LLM serves as a gateway for legal professionals seeking to excel in their specialized areas, contributing to the dynamic and evolving landscape of law and its applications across various domains globally.ChatGPT stands as a pinnacle in natural language processing, representing an advanced form of AI-driven conversational models. Developed by OpenAI, ChatGPT harnesses the power of deep learning and large-scale neural networks to understand, generate, and respond to human language. It\\'s a cutting-edge language model designed to comprehend context, structure, and nuances in conversations, enabling it to produce coherent and contextually relevant responses.\", metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\"In essence, the bard was a revered figure, an artist, historian, and custodian of culture, whose legacy continues to resonate through literary traditions and the enduring enchantment of their timeless tales.ChatGPT is an advanced language model developed by OpenAI, specifically designed for natural language processing (NLP) and generating human-like text. It\\'s part of the broader GPT (Generative Pre-trained Transformer) series, renowned for its proficiency in understanding, generating, and responding to text-based inputs.\", metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'}), Document(page_content=\\'Moreover, LangChain envisions a community-driven approach, where stakeholders actively engage, contribute, and shape the development of language technologies. Through open-source frameworks and participatory governance, it fosters an inclusive environment for developers, researchers, linguists, and language enthusiasts to collaborate, share insights, and co-create transformative language solutions.\\', metadata={\\'source\\': \\'C:\\\\\\\\Users\\\\\\\\Kushal.Sharma\\\\\\\\Desktop\\\\\\\\Example_Rag.txt\\'})]\\nGenerate a response to the query: what is chatgpt '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"Given the following text chunks:\\n{results}\\nGenerate a response to the query: {query}\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59251ba6",
   "metadata": {},
   "source": [
    "## API Call to Generate Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "911b7ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT is a conversational AI model from Google that's trained to understand and generate human language. It's proficient in understanding context, structure, and nuances in conversations, enabling it to provide informative and contextually relevant responses. Its extensive training on vast amounts of text data allows it to generate coherent text across diverse domains and conversational contexts. ChatGPT finds application in customer service, content generation, language translation, educational assistance, and more.\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(prompt)\n",
    "print(response.text) # This response in fetch from the top k chunks stored in results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c19ed",
   "metadata": {},
   "source": [
    "## Overall Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbaa70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain \n",
    "pip install google-generativeai\n",
    "pip install langchain-google-genai\n",
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1272e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "# Load the document, split it into chunks, embed each chunk, and load it into the vector store.\n",
    "raw_documents = TextLoader(r'C:xyz.txt').load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=20, chunk_overlap=5)    # take 1/5 ratio mostly \n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "for chunks in documents:\n",
    "    print(chunks)\n",
    "\n",
    "# Replace 'model_name' with the actual model name or identifier\n",
    "model_name = \"models/embedding-001\"\n",
    "api_key = \"your_api_key\"  # Replace with your Google API key\n",
    "\n",
    "embeddingsss = GoogleGenerativeAIEmbeddings(model=model_name, google_api_key=api_key)\n",
    "\n",
    "db = FAISS.from_documents(documents, embeddingsss)\n",
    "\n",
    "query = \"what is chatgpt \"\n",
    "embedding_vector = embeddingsss.embed_query(query)\n",
    "docs_and_scores = db.similarity_search_by_vector(embedding_vector)\n",
    "\n",
    "print(docs_and_scores[0].page_content)\n",
    "\n",
    "    \n",
    "\n",
    "results_with_scores = db.similarity_search_with_score(query)\n",
    "for doc, score in results_with_scores:\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}, Score: {score}\")\n",
    "\n",
    "docs = db.similarity_search_with_score(query)\n",
    "docs\n",
    "\n",
    "results = db.similarity_search(query , k= 10)\n",
    "for doc in results:\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}\")\n",
    "\n",
    "prompt = f\"Given the following text chunks:\\n{results}\\nGenerate a response to the query: {query}\"\n",
    "prompt\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
